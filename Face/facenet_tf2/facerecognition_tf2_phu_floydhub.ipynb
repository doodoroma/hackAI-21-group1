{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzfAdx1KwcSt"
   },
   "source": [
    "## **1. Install Vesion 1.1.0 de scipy (comptabile avec code d'aligment d'images)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKlccNxZkRYg",
    "outputId": "ddb4bac0-85c9-4097-f770-781dab2369d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2MB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/site-packages (from scipy==1.1.0) (1.17.4)\n",
      "Installing collected packages: scipy\n",
      "  Found existing installation: scipy 1.3.3\n",
      "    Uninstalling scipy-1.3.3:\n",
      "      Successfully uninstalled scipy-1.3.3\n",
      "Successfully installed scipy-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROzjUeFbwvh0"
   },
   "source": [
    "## **2. Télécharger le projet de reconnaissance faciale (adapté pour tf 2.x))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogcgA12Veb2b",
    "outputId": "98cd6a24-93db-44e6-fc7f-edead686de71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'facenet_tf2'...\n",
      "remote: Enumerating objects: 131, done.\u001b[K\n",
      "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
      "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
      "remote: Total 131 (delta 29), reused 128 (delta 29), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (131/131), 10.80 MiB | 21.22 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sidimahmoudi/facenet_tf2.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7RGASELeipM",
    "outputId": "3c715972-26b1-4417-c2e0-86a7c70a5427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/floyd/home/facenet_tf2\n"
     ]
    }
   ],
   "source": [
    "cd facenet_tf2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dkva5qs9w9YD"
   },
   "source": [
    "## **3. Télécharger/décompresser la BD de visages non croppés (A augmenter)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aNqS7KCTelv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ZIP.or PERSONS.zip or open PERSONS.zip\n"
     ]
    }
   ],
   "source": [
    "#! wget https://cluster.ig.umons.ac.be/workshop_ia/PERSONS.zip\r\n",
    "! unzip PERSONS.zip\r\n",
    "! rm PERSONS.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXJ2oqwRxVMS"
   },
   "source": [
    "## **4. Telecherger un modèle préentrainé pour la reconnaissance faciale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HI4HNP93plYF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-09 16:44:50--  https://github.com/sidimahmoudi/facenet_tf2/releases/download/facemodel/20180408-102900.pb%0D\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2021-03-09 16:44:50 ERROR 404: Not Found.\n",
      "\n",
      "mv: cannot stat '20180408-102900.pb': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! mkdir model_checkpoints\r\n",
    "! wget https://github.com/sidimahmoudi/facenet_tf2/releases/download/facemodel/20180408-102900.pb\r\n",
    "! mv 20180408-102900.pb model_checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLjg5rQKxg4e"
   },
   "source": [
    "## **5. Aligenement (crop) des images (visages)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yn94OoBlrXgo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 08:11:38.977943: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "2021-03-13 08:11:39.000266: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\n",
      "2021-03-13 08:11:39.000453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e4cb66e0d0 executing computations on platform Host. Devices:\n",
      "2021-03-13 08:11:39.000477: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /floyd/home/facenet_tf2/facenet/src/align/detect_face.py:213: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "2021-03-13 08:13:37.086828: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 87095556 exceeds 10% of system memory.\n",
      "2021-03-13 08:13:37.146439: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 289883160 exceeds 10% of system memory.\n",
      "2021-03-13 08:13:38.399425: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 289883160 exceeds 10% of system memory.\n",
      "2021-03-13 08:13:38.399425: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 289883160 exceeds 10% of system memory.\n",
      "2021-03-13 08:13:38.926907: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 72525200 exceeds 10% of system memory.\n"
     ]
    }
   ],
   "source": [
    "!python3 facenet/src/align_dataset_mtcnn.py /floyd/input/persons persons_aligned > out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  \u001b[0m\u001b[01;34mfacenet\u001b[0m/  \u001b[01;34mmodel_checkpoints\u001b[0m/  out.txt  \u001b[01;34mpersons_aligned\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJtCUPITxuST"
   },
   "source": [
    "## **6. Génération du nouveau modèle \"my_classifier.pkl\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MLT5nT7stmUc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facenet/src/classifier.py:59: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')\n",
      "2021-03-10 19:49:41.780249: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "2021-03-10 19:49:41.802816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500005000 Hz\n",
      "2021-03-10 19:49:41.803004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563fb6e6a550 executing computations on platform Host. Devices:\n",
      "2021-03-10 19:49:41.803030: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Number of classes: 9\n",
      "Number of images: 3735\n",
      "Loading feature extraction model\n",
      "Model filename: model_checkpoints/20180408-102900.pb\n",
      "WARNING:tensorflow:From /floyd/home/facenet_tf2/facenet/src/facenet.py:375: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Calculating features for images\n",
      "Training classifier\n",
      "Saved classifier model to file \"model_checkpoints/my_classifier.pkl\"\n"
     ]
    }
   ],
   "source": [
    "!python3 facenet/src/classifier.py TRAIN persons_aligned/ model_checkpoints/20180408-102900.pb model_checkpoints/my_classifier.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuejwK35x69K"
   },
   "source": [
    "## **7. Tester le modèle en offline avec la vidéo \"video.mp4\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MVx-d1szmlO-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"facenet/contributed/offline_face_recognition.py\", line 34, in <module>\n",
      "    from google.colab import files\n",
      "ModuleNotFoundError: No module named 'google.colab'\n"
     ]
    }
   ],
   "source": [
    "!python3 facenet/contributed/offline_face_recognition.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TH9dAUoyI_j"
   },
   "source": [
    "## **8. Résultats**\r\n",
    "\r\n",
    "\r\n",
    "1.   Offline : via la vidéo \"output.mp4\"\r\n",
    "2.   Online: en utilisant le script \"contributed/real_time_face_recongition\" mais le faire fonctionner il faudra installa tesnorflow en local ou sur le carte embarqué \"Jeston\"\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Face_recognition_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
